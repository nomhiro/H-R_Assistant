import pymupdf
import tempfile
import base64
import logging
from PIL import Image
from io import BytesIO

from urllib.parse import urlparse
from langchain_text_splitters import CharacterTextSplitter
from azure.storage.blob import BlobServiceClient

from domain.obj_cosmos_page import CosmosPageObj
from domain.document_structure import DocumentStructure
from service.openai_service.openai_service import AzureOpenAIService
from service.cosmos_service.cosmos_service import CosmosService

def regist_pdf(azure_openai_service: AzureOpenAIService, 
                 cosmos_service: CosmosService, 
                 blob_service_client: BlobServiceClient,
                 data_as_file: BytesIO,
                 STR_AI_SYSTEMMESSAGE: str,
                 BLOB_CONTAINER_NAME_IMAGE: str,
                 MAX_CONTENT_LENGTH: int,
                 file_name: str,
                 blob_url: str):
    # Create a temporary file
    temp_path = ""
    with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as temp:
        temp.write(data_as_file.read())
        temp_path = temp.name

    doc = pymupdf.open(temp_path)
    # ãƒšãƒ¼ã‚¸æ•°ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
    logging.info(f"ğŸš€PDF Page count : {doc.page_count}")

    # ãƒšãƒ¼ã‚¸ã”ã¨ã«CosmosDBã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ä½œæˆã—ã€ãƒšãƒ¼ã‚¸ç”»åƒãŒã‚ã‚‹å ´åˆã¯ãƒšãƒ¼ã‚¸ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’Blobã«ã‚’ä½œæˆ
    for page in doc:  # iterate through the pages
        logging.info(f"ğŸš€Page Number: {page.number}")
        pix = page.get_pixmap()  # render page to an image
        # Convert the pixmap to a PIL Image
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

        binary_data = BytesIO()
        img.save(binary_data, format='PNG')
        binary_data.seek(0)
        base64_data = base64.b64encode(binary_data.getvalue()).decode()
        
        # OpenAIã«æ¨è«–ã•ã›ã‚‹ãŸã‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
        image_content = []
        image_content.append({
            "type": "image_url",
            "image_url": 
            {
                "url": f"data:image/jpeg;base64,{base64_data}"
            },
        })
        messages = []
        messages.append({"role": "system", "content": STR_AI_SYSTEMMESSAGE})
        messages.append({"role": "user", "content": image_content})
        
        try:
            # GPT4oã«ã¯jsonãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæŒ‡å®šãŒãªã„ã®ã§ä½¿ãˆãªã„ã€‚
            response = azure_openai_service.getChatCompletionJsonStructuredMode(messages, 0, 0, DocumentStructure)
        except Exception as e:     
            # ã‚¨ãƒ©ãƒ¼ãŒã€ŒCould not parse response content as the length limit was reachedã€ã®å ´åˆã€ãã®ãƒšãƒ¼ã‚¸ã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹
            if "Could not parse response content as the length limit was reached" in str(e):
                logging.warning(f"ğŸš€âŒError page {page.number} of doc '{file_name}': {e}")
                continue
        
        # Check and truncate the response content if necessary
        doc_structured = response.choices[0].message.parsed
        if len(doc_structured.content) > MAX_CONTENT_LENGTH:
            logging.warning(f"Response content length ({len(doc_structured.content)}) exceeds the limit. Truncating to {MAX_CONTENT_LENGTH} characters.")
            doc_structured.content = doc_structured.content[:MAX_CONTENT_LENGTH]

        logging.info(f"ğŸš€Response Format: {doc_structured}")
        
        # contentã‚’ãƒ™ã‚¯ãƒˆãƒ«å€¤ã«å¤‰æ›
        # docu_structured.contentã¯8192ãƒˆãƒ¼ã‚¯ãƒ³ä»¥å†…ã«ã™ã‚‹
        text_splitter = CharacterTextSplitter.from_tiktoken_encoder(
            model_name="gpt-4", chunk_size=7000, chunk_overlap=0
        )
        spilitted_doc_structured = text_splitter.split_text(doc_structured.content)
        content_vector = azure_openai_service.getEmbedding(spilitted_doc_structured)
        
        # is_contain_imageãŒTrueã®å ´åˆã¯ã€StorageAccountã®Blobã®"rag-images"ã«ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if doc_structured.is_contain_image:
            # æ ¼ç´ã™ã‚‹ãƒ‘ã‚¹ã‚’ç”Ÿæˆã€‚Triggerã•ã‚ŒãŸBlobã®ãƒ‘ã‚¹ã®ãƒ•ã‚©ãƒ«ãƒ€ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã€æ ¼ç´å…ˆãƒ•ã‚©ãƒ«ãƒ€ã«ã™ã‚‹ã€‚
            parsed_url = urlparse(blob_url)
            path_parts = parsed_url.path.split('/')
            index = path_parts.index('rag-docs')
            
            stored_image_path = file_name + "_page" + str(page.number) + ".png"
            
            blob_client = blob_service_client.get_blob_client(container=BLOB_CONTAINER_NAME_IMAGE, blob=stored_image_path)
            blob_client.upload_blob(base64.b64decode(base64_data), overwrite=True)
            logging.info(f"ğŸš€Uploaded Image to Blob: {stored_image_path}")
        
        # CosmosDBã«ç™»éŒ²ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        cosmos_page_obj = CosmosPageObj(file_name=file_name,
                                        file_path=blob_url,
                                        page_number=page.number,
                                        content=doc_structured.content, 
                                        content_vector=content_vector,
                                        keywords=doc_structured.keywords,
                                        delete_flag=False,
                                        is_contain_image=doc_structured.is_contain_image,
                                        image_blob_path=stored_image_path if doc_structured.is_contain_image else None)
        
        cosmos_service.insert_data(cosmos_page_obj.to_dict())
        
    # tempã‚’å‰Šé™¤
    temp.close()